{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2주차.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-xd8vO2-Pa"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
        "from tqdm import tqdm\n",
        "import lightgbm as lgbm\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestRegressor \n",
        "\n",
        "import os\n",
        "import json\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Dense, Activation, Conv2D, Flatten,MaxPooling2D,BatchNormalization,Lambda, AveragePooling2D\n",
        "import keras.backend as K\n",
        "from keras.regularizers import l1_l2\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback, EarlyStopping\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD6CcreH3JMB",
        "outputId": "b0bdbe4c-039b-47fa-ce1b-6a9427cd8f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"keras_version : \" + str(keras.__version__))\n",
        "print(\"numpy_version : \" + str(np.__version__))\n",
        "print(\"pandas_version : \" + str(pd.__version__))\n",
        "print(\"tensorflow_version :\" + str(tf.__version__))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras_version : 2.4.3\n",
            "numpy_version : 1.18.5\n",
            "pandas_version : 1.1.4\n",
            "tensorflow_version :2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6otcMke1W27",
        "outputId": "34420565-9e98-45ca-b9e7-f7da0ca9874e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/My Drive/Dacon_튜터/train_features.csv\", index_col=0)\n",
        "test = pd.read_csv(\"/content/drive/My Drive/Dacon_튜터/test_features.csv\", index_col=0)\n",
        "y_train = pd.read_csv(\"/content/drive/My Drive/Dacon_튜터/train_target.csv\", index_col=0)\n",
        "y_test = pd.read_csv(\"/content/drive/My Drive/Dacon_튜터/sample_submission.csv\", index_col=0)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8--hBfb27Os"
      },
      "source": [
        "def transform1(train, n1, n2):\n",
        "    train_time = train.copy()\n",
        "    train_time['S1'] = [1 if i != 0 else 0 for i in train['S1']]\n",
        "    train_time['S2'] = [1 if i != 0 else 0 for i in train['S2']]\n",
        "    train_time['S3'] = [1 if i != 0 else 0 for i in train['S3']]\n",
        "    train_time['S4'] = [1 if i != 0 else 0 for i in train['S4']]\n",
        "    train_time.drop(['Time'], axis=1, inplace=True)\n",
        "    \n",
        "    train_time = train_time.sum(axis=1)\n",
        "    train_time = train_time.transform(lambda x: (x-x.mean())/(x.std()))\n",
        "    train_time = np.array(train_time).reshape(n1, n2, 1, 1)\n",
        "    \n",
        "    return train_time"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaWrzuFp3ZFp"
      },
      "source": [
        "train = train.transform(lambda x: (x-x.mean())/(x.std()))\n",
        "test = test.transform(lambda x: (x-x.mean())/(x.std()))\n",
        "\n",
        "###\n",
        "\n",
        "X_data = train.iloc[:,:]\n",
        "X_data = np.array(X_data).reshape((2800,375,5,1))\n",
        "\n",
        "X_data_test = test.iloc[:,:]\n",
        "X_data_test = np.array(X_data_test).reshape((700,375,5,1))\n",
        "\n",
        "Y_data = np.array(y_train.copy())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI-kNUcS3iTL"
      },
      "source": [
        "X_data_Case4 = X_data.copy()\n",
        "X_data_test_Case4 = X_data_test.copy()\n",
        "Y_data_Case4 = Y_data.copy()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7WoSd3g31Ab"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXeAvnOZ344y"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkMTN-yo3461"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAYXsmQn4Yk6"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raHT9Sf14ZXz"
      },
      "source": [
        "모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx-p2Iw135BT"
      },
      "source": [
        "import math\n",
        "from keras.callbacks import Callback\n",
        "class CosineAnnealingScheduler(Callback):\n",
        "    \"\"\"Cosine annealing scheduler.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T_max, eta_max, eta_min=0, verbose=0):\n",
        "        super(CosineAnnealingScheduler, self).__init__()\n",
        "        self.T_max = T_max\n",
        "        self.eta_max = eta_max\n",
        "        self.eta_min = eta_min\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        if not hasattr(self.model.optimizer, 'lr'):\n",
        "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
        "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "        #if self.verbose &gt; 0:\n",
        "        #    print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
        "        #          'rate to %s.' % (epoch + 1, lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = K.get_value(self.model.optimizer.lr)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIOAGJUD35gu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def kaeri_metric(y_true, y_pred):\n",
        "    '''\n",
        "    y_true: dataframe with true values of X,Y,M,V\n",
        "    y_pred: dataframe with pred values of X,Y,M,V\n",
        "    \n",
        "    return: KAERI metric\n",
        "    '''\n",
        "    \n",
        "    return 0.5 * E1(y_true, y_pred) + 0.5 * E2(y_true, y_pred)\n",
        "\n",
        "\n",
        "### E1과 E2는 아래에 정의됨 ###\n",
        "\n",
        "def E1(y_true, y_pred):\n",
        "    '''\n",
        "    y_true: dataframe with true values of X,Y,M,V\n",
        "    y_pred: dataframe with pred values of X,Y,M,V\n",
        "    \n",
        "    return: distance error normalized with 2e+04\n",
        "    '''\n",
        "    \n",
        "    _t, _p = np.array(y_true)[:,:2], np.array(y_pred)[:,:2]\n",
        "    \n",
        "    return np.mean(np.sum(np.square(_t - _p), axis = 1) / 2e+04)\n",
        "\n",
        "\n",
        "def E2(y_true, y_pred):\n",
        "    '''\n",
        "    y_true: dataframe with true values of X,Y,M,V\n",
        "    y_pred: dataframe with pred values of X,Y,M,V\n",
        "    \n",
        "    return: sum of mass and velocity's mean squared percentage error\n",
        "    '''\n",
        "    \n",
        "    _t, _p = np.array(y_true)[:,2:], np.array(y_pred)[:,2:]\n",
        "    \n",
        "    \n",
        "    return np.mean(np.sum(np.square((_t - _p) / (_t + 1e-06)), axis = 1))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IipCpSyu37f9"
      },
      "source": [
        "weight1 = np.array([1,1,0,0])\n",
        "weight2 = np.array([0,0,1,1])\n",
        "\n",
        "def my_loss(y_true, y_pred):\n",
        "    divResult = Lambda(lambda x: x[0]/x[1])([(y_pred-y_true),(y_true+0.000001)])\n",
        "    return K.mean(K.square(divResult))\n",
        "\n",
        "\n",
        "def my_loss_E1(y_true, y_pred):\n",
        "    return K.mean(K.square(y_true-y_pred)*weight1)/2e+04\n",
        "\n",
        "def my_loss_E2(y_true, y_pred):\n",
        "    divResult = Lambda(lambda x: x[0]/x[1])([(y_pred-y_true),(y_true+0.000001)])\n",
        "    return K.mean(K.square(divResult)*weight2)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5mK99HA39IW"
      },
      "source": [
        "def plot_error(type_id,pred,true):\n",
        "    print(pred.shape)\n",
        "\n",
        "    if type_id == 0:\n",
        "        _name = 'x_pos'\n",
        "    elif type_id == 1:\n",
        "        _name = 'y_pos'\n",
        "    elif type_id == 2:\n",
        "        _name = 'mass'\n",
        "    elif type_id == 3:\n",
        "        _name = 'velocity'\n",
        "    elif type_id == 4:\n",
        "        _name = \"distance\"\n",
        "    else:\n",
        "        _name = 'error'\n",
        "\n",
        "    x_coord = np.arange(1,pred.shape[0]+1,1)\n",
        "    if type_id < 2:\n",
        "        Err_m = (pred[:,type_id] - true[:,type_id])\n",
        "    elif type_id < 4:\n",
        "        Err_m = ((pred[:,type_id] - true[:,type_id])/true[:,type_id])*100\n",
        "    else:\n",
        "        Err_m = ((pred[:,0]-true[:,0])**2+(pred[:,1]-true[:,1])**2)**0.5\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(8,6))\n",
        "    # plt.rcParams[\"font.family\"]=\"Times New Roman\"\n",
        "    plt.rcParams[\"font.size\"]=15\n",
        "    plt.scatter(x_coord, Err_m, marker='o')\n",
        "    plt.title(\"%s Prediction for Training Data\" % _name, size=20)\n",
        "    plt.xlabel(\"Data ID\", labelpad=10, size=20)\n",
        "    plt.ylabel(\"Prediction Error of %s,\" % _name, labelpad=10, size=20)\n",
        "    plt.xticks(size=15)\n",
        "    plt.yticks(size=15)\n",
        "    plt.ylim(-100., 100.)\n",
        "    plt.xlim(0, pred.shape[0]+1)\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "    print(np.std(Err_m))\n",
        "    print(np.max(Err_m))\n",
        "    print(np.min(Err_m))\n",
        "    return Err_m"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAavz4wl3_45"
      },
      "source": [
        "def set_model(train_target, n_sam,n_col, regularizer_True):  # 0:x,y, 1:m, 2:v\n",
        "    \n",
        "    activation = 'elu'\n",
        "    padding = 'same'\n",
        "    model = Sequential()\n",
        "    nf = 16\n",
        "    fs = (3,1)\n",
        "    \n",
        "    model.add(Conv2D(nf,fs, padding=padding, activation=activation,input_shape=(n_sam,n_col,1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "\n",
        "    model.add(Conv2D(nf*2,fs, padding=padding, activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "\n",
        "    model.add(Conv2D(nf*4,fs, padding=padding, activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "\n",
        "    model.add(Conv2D(nf*8,fs, padding=padding, activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "\n",
        "    model.add(Conv2D(nf*16,fs, padding=padding, activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "\n",
        "    model.add(Conv2D(nf*32,fs, padding=padding, activation=activation))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 1)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation ='elu'))\n",
        "    model.add(Dense(64, activation ='elu'))\n",
        "    model.add(Dense(32, activation ='elu'))\n",
        "    model.add(Dense(16, activation ='elu'))\n",
        "    \n",
        "    if regularizer_True:\n",
        "        model.add(Dense(4, kernel_regularizer=l1_l2(l1=0.001)))\n",
        "    else:\n",
        "        model.add(Dense(4))\n",
        "    \n",
        "\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    #optimizer = keras.optimizers.RMSprop()\n",
        "    \n",
        "    global weight2\n",
        "    if train_target == 1: # only for M\n",
        "        weight2 = np.array([0,0,1,0])\n",
        "    else: # only for V\n",
        "        weight2 = np.array([0,0,0,1])\n",
        "       \n",
        "    if train_target==0:\n",
        "        model.compile(loss=my_loss_E1,\n",
        "                  optimizer=optimizer,\n",
        "                 )\n",
        "    else:\n",
        "        model.compile(loss=my_loss_E2,\n",
        "                  optimizer=optimizer,\n",
        "                 )\n",
        "       \n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_eo_i0j4C3C"
      },
      "source": [
        "def train_CNN(model,X,Y,X_val,Y_val, save_point, enum, train_target, scheduler_True):\n",
        "    \n",
        "    from numpy.random import seed\n",
        "    seed(777)\n",
        "    \n",
        "    MODEL_SAVE_FOLDER_PATH = './model/'\n",
        "    if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
        "        os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
        "\n",
        "    model_path = MODEL_SAVE_FOLDER_PATH + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
        "    best_save = ModelCheckpoint('best_m_' + str(save_point) + \"_\" + str(enum) + \"_\" + str(train_target) + '.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "    cosine_scheduler = CosineAnnealingScheduler(T_max=100, eta_max=6e-3, eta_min=1e-6)\n",
        "\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=patience)\n",
        "    \n",
        "    my_seed = 777\n",
        "    np.random.seed(my_seed)\n",
        "    if scheduler_True:\n",
        "        history = model.fit(X, Y,\n",
        "                      epochs=10000,\n",
        "                      batch_size=128,\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_val, Y_val),\n",
        "                      verbose = 2,\n",
        "                      callbacks=[best_save, early_stop,cosine_scheduler],\n",
        "                      )\n",
        "    else:\n",
        "        history = model.fit(X, Y,\n",
        "                      epochs=10000,\n",
        "                      batch_size=128,\n",
        "                      shuffle=True,\n",
        "                      validation_data=(X_val, Y_val),\n",
        "                      verbose = 2,\n",
        "                      callbacks=[best_save, early_stop],\n",
        "                      )\n",
        "    \n",
        "\n",
        "    fig, loss_ax = plt.subplots()\n",
        "    acc_ax = loss_ax.twinx()\n",
        "\n",
        "    loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "    loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "    loss_ax.set_xlabel('epoch')\n",
        "    loss_ax.set_ylabel('loss')\n",
        "    loss_ax.legend(loc='upper left')\n",
        "    plt.show()    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUxpIk3P4H1m"
      },
      "source": [
        "def load_best_model(train_target, save_point, enum):\n",
        "\n",
        "    if train_target == 0:\n",
        "        model = load_model('best_m_' + str(save_point) + \"_\" + str(enum) + \"_\" + str(train_target) + '.hdf5' , custom_objects={'my_loss_E1': my_loss, })\n",
        "    else:\n",
        "        model = load_model('best_m_' + str(save_point) + \"_\" + str(enum) + \"_\" + str(train_target) + '.hdf5' , custom_objects={'my_loss_E2': my_loss, })\n",
        "\n",
        "    score = model.evaluate(X_data, Y_data, verbose=0)\n",
        "    print('loss:', score)\n",
        "\n",
        "    pred = model.predict(X_data)\n",
        "\n",
        "    i=0\n",
        "\n",
        "    print('정답(original):', Y_data[i])\n",
        "    print('예측값(original):', pred[i])\n",
        "\n",
        "    print(E1(pred, Y_data))\n",
        "    print(E2(pred, Y_data))\n",
        "    #print(E2M(pred, Y_data))\n",
        "    #print(E2V(pred, Y_data))    \n",
        "    \n",
        "    if train_target ==0:\n",
        "        plot_error(4,pred,Y_data)\n",
        "    elif train_target ==1:\n",
        "        plot_error(2,pred,Y_data)\n",
        "    elif train_target ==2:\n",
        "        plot_error(3,pred,Y_data)    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCuxeDCb4IMW"
      },
      "source": [
        "lr = 3e-4\n",
        "lr_d = 0.0\n",
        "patience = 30\n",
        "dr_rate = 0\n",
        "\n",
        "def run_model(X_data, X_data_test, Y_data, save_point,scheduler_True,regularizer_True):\n",
        "    submit = pd.read_csv(\"/content/drive/My Drive/Dacon_튜터/sample_submission.csv\", index_col=0)\n",
        "    submit.iloc[:,:] = 0\n",
        "\n",
        "    lr = 3e-4\n",
        "    lr_d = 0.0\n",
        "    patience = 30\n",
        "    dr_rate = 0\n",
        "    \n",
        "    n_col = X_data.shape[2]\n",
        "    n_sam = X_data.shape[1]\n",
        "    \n",
        "    for enum, (train_index,valid_index) in enumerate(kf.split(X_data)):\n",
        "        X_train = X_data[train_index]\n",
        "        Y_train = Y_data[train_index]\n",
        "    \n",
        "        X_val = X_data[valid_index]\n",
        "        Y_val = Y_data[valid_index]\n",
        "    \n",
        "    \n",
        "        for train_target in range(3):\n",
        "            model = set_model(train_target, n_sam,n_col, regularizer_True)\n",
        "        \n",
        "            train_CNN(model,X_train, Y_train, X_val, Y_val, save_point, enum, train_target,scheduler_True)    \n",
        "            best_model = load_best_model(train_target, save_point, enum)\n",
        "\n",
        "   \n",
        "            pred_data_test = best_model.predict(X_data_test)\n",
        "            pred_data_valid = best_model.predict(X_val)\n",
        "    \n",
        "            if train_target == 0: # x,y 학습\n",
        "                submit.iloc[:,0] += pred_data_test[:,0]/5\n",
        "                submit.iloc[:,1] += pred_data_test[:,1]/5\n",
        "                \n",
        "            elif train_target == 1: # m 학습\n",
        "                submit.iloc[:,2] += pred_data_test[:,2]/5\n",
        "        \n",
        "            elif train_target == 2: # v 학습\n",
        "                submit.iloc[:,3] += pred_data_test[:,3]/5    \n",
        "    \n",
        "    return submit"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GtIUL2m5v1n"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX6dW3PC6rRh",
        "outputId": "2bae3ed5-15f7-448e-ebff-73176f3eb521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_data.shape"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 375, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtlcLuOC6rTi",
        "outputId": "482b8440-6db0-4129-da4f-a5d60cc8a346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Case4 nrow : \" + str(X_data_Case4.shape[1]) + \" / Case4 ncol : \" + str(X_data_Case4.shape[2]))\n",
        "print(\"Case4 nrow : \" + str(X_data_test_Case4.shape[1]) + \" / Case4 ncol : \" + str(X_data_test_Case4.shape[2]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Case4 nrow : 375 / Case4 ncol : 5\n",
            "Case4 nrow : 375 / Case4 ncol : 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JoNNTnC7AYI",
        "outputId": "edcc3e7d-795f-400e-fb0a-918497847e54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_data_Case4.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2800, 375, 5, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBNjRYi14MlB",
        "outputId": "913c6f69-c7f2-4c0a-a453-71feab9000d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "submit = run_model(X_data,X_data_test, Y_data, 1,True,False)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 375, 5, 16)        64        \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 375, 5, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 187, 5, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 187, 5, 32)        1568      \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 187, 5, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 93, 5, 32)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 93, 5, 64)         6208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 93, 5, 64)         256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 46, 5, 64)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 46, 5, 128)        24704     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 46, 5, 128)        512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 23, 5, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 23, 5, 256)        98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 23, 5, 256)        1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 11, 5, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 11, 5, 512)        393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 11, 5, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 12800)             0         \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 128)               1638528   \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 4)                 68        \n",
            "=================================================================\n",
            "Total params: 2,178,324\n",
            "Trainable params: 2,176,308\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-f117f944828d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-b2377437a7b6>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(X_data, X_data_test, Y_data, save_point, scheduler_True, regularizer_True)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_sam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer_True\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mtrain_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_True\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-69020ecba463>\u001b[0m in \u001b[0;36mtrain_CNN\u001b[0;34m(model, X, Y, X_val, Y_val, save_point, enum, train_target, scheduler_True)\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                       \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosine_scheduler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                       )\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         if x is not None)\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m     \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    396\u001b[0m       \u001b[0;31m# Check for any resource inputs. If we find any, we update control_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m       \u001b[0;31m# and last_write_to_resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0mis_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResourceType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0minput_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;34m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m   \u001b[0mreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_read_write_resource_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m   \u001b[0msaturated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msaturated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py\u001b[0m in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mread_only_input_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAD_ONLY_RESOURCE_INPUTS_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2484\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2486\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2487\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, op, message)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;34m\"\"\"Creates an `InvalidArgumentError`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     super(InvalidArgumentError, self).__init__(node_def, op, message,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}